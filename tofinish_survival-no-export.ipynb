{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK\n",
    "import itertools\n",
    "import sys\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchvision import models\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "SOURCE_PATH = Path(os.getcwd()) / \"src\"\n",
    "\n",
    "if SOURCE_PATH not in sys.path:\n",
    "    sys.path.append(SOURCE_PATH)\n",
    "\n",
    "from src.extraction import (\n",
    "    extract_images_in_survival_order,\n",
    ")\n",
    "\n",
    "from src.plots import (\n",
    "    plot_observation,\n",
    "    plot_deeplab_mobile_predictions,\n",
    "    plot_mobile_prediction_from_path,\n",
    ")\n",
    "\n",
    "from src.deeplab_mobile.modelling import (\n",
    "    select_images_input,\n",
    "    get_deeplab_mobile_model,\n",
    "    train_deeplab_mobile,\n",
    ")\n",
    "\n",
    "from src.deeplab_mobile.segdataset import get_mobile_dataloaders\n",
    "\n",
    "from src.utils import LOGS_FILE_PATH, TYPE_NAMES\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(os.getcwd()) / \"data\" / \"HGG\"\n",
    "survival = pd.read_csv(data_path.parent / \"survival_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ids = survival[\"BraTS19ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2, t1ce, t1, flair, seg = extract_images_in_survival_order(data_path, dir_ids)\n",
    "images = [t2, t1ce, t1, flair, seg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(TYPE_NAMES)):\n",
    "    survival[TYPE_NAMES[i]] = images[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = \"flair_totalpipe_old.pt\"\n",
    "model = torch.load(Path(os.getcwd()) / \"models\" / modelname)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair_segout = []\n",
    "\n",
    "for i in range(len(survival)):\n",
    "    input_tensor = (\n",
    "        torch.tensor(survival[\"flair\"][i])\n",
    "        .expand(3, -1, -1)\n",
    "        .type(torch.ShortTensor)\n",
    "        .float()\n",
    "        .unsqueeze(0)\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)[\"out\"][0][0]\n",
    "    flair_segout.append(np.array(output))\n",
    "\n",
    "survival[\"flair_seg\"] = flair_segout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survival = survival.dropna().reset_index(drop=True)\n",
    "survival[\"Survival\"] = survival[\"Survival\"].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = []\n",
    "for i in range(len(survival)):\n",
    "    if \"ALIVE\" in survival[\"Survival\"].loc[i]:\n",
    "        to_drop.append(i)\n",
    "\n",
    "\n",
    "survival.drop(to_drop, inplace=True)\n",
    "print(len(survival))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survival[\"Survival\"] = survival[\"Survival\"].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_img, age):\n",
    "    base_model = keras.applications.resnet50.ResNet50(\n",
    "        weights=\"imagenet\", include_top=False, input_tensor=input_img\n",
    "    )\n",
    "    a = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    a = keras.layers.concatenate([a, age])\n",
    "    a = keras.layers.BatchNormalization()(a)\n",
    "    output = keras.layers.Dense(1)(a)\n",
    "\n",
    "    model = keras.models.Model(inputs=[input_img, age], outputs=output)\n",
    "    return model, base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(51984, 1200)\n",
    "        self.fc2 = nn.Linear(1200, 340)\n",
    "        self.fc3 = nn.Linear(340, 30)\n",
    "        self.fc4 = nn.Linear(30, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class Survival_Dataset(Dataset):\n",
    "    def __init__(\n",
    "        self, images, targets, fraction=0.1, subset=None, image_color_mode=\"rgb\"\n",
    "    ) -> None:\n",
    "\n",
    "        if image_color_mode not in [\"rgb\", \"grayscale\"]:\n",
    "            raise ValueError(\n",
    "                f\"{image_color_mode} is an invalid choice. Please enter from rgb grayscale.\"\n",
    "            )\n",
    "\n",
    "        self.image_color_mode = image_color_mode\n",
    "\n",
    "        if subset not in [\"Train\", \"Test\"]:\n",
    "            raise (\n",
    "                ValueError(\n",
    "                    f\"{subset} is not a valid input. Acceptable values are Train and Test.\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.fraction = fraction\n",
    "        self.images = images\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        image = self.images[index]\n",
    "        target = self.targets[index]\n",
    "\n",
    "        sample = {\"image\": image, \"target\": target}\n",
    "        sample[\"image\"] = (\n",
    "            torch.tensor(sample[\"image\"]).expand(3, -1, -1).type(torch.ShortTensor)\n",
    "        )\n",
    "        sample[\"target\"] = target\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_survival_dataloaders(images, target, batch_size=14):\n",
    "    image_datasets = {\n",
    "        x: Survival_Dataset(images, target, subset=x) for x in [\"Train\", \"Test\"]\n",
    "    }\n",
    "\n",
    "    dataloaders = {\n",
    "        x: DataLoader(\n",
    "            image_datasets[x],\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "        for x in [\"Train\", \"Test\"]\n",
    "    }\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = get_survival_dataloaders(\n",
    "    survival[\"flair\"].values, survival[\"Survival\"].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 2\n",
    "metrics = {\"f1_score\": f1_score}\n",
    "running_loss = 0.0\n",
    "best_loss = 1e10\n",
    "\n",
    "since = time.time()\n",
    "best_model_wts = copy.deepcopy(net.state_dict())\n",
    "\n",
    "\n",
    "fieldnames = (\n",
    "    [\"epoch\", \"Train_loss\", \"Test_loss\"]\n",
    "    + [f\"Train_{m}\" for m in metrics.keys()]\n",
    "    + [f\"Test_{m}\" for m in metrics.keys()]\n",
    ")\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(\"Epoch {}/{}\".format(epoch, num_epochs))\n",
    "    print(\"-\" * 10)\n",
    "\n",
    "    batchsummary = {a: [0] for a in fieldnames}\n",
    "\n",
    "    for phase in [\"Train\", \"Test\"]:\n",
    "        if phase == \"Train\":\n",
    "            net.train()\n",
    "        else:\n",
    "            net.eval()\n",
    "\n",
    "        for sample in tqdm(iter(dataloaders[phase])):\n",
    "            inputs = sample[\"image\"].float()\n",
    "            targets = sample[\"target\"].float()\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == \"Train\"):\n",
    "                outputs = net(inputs).squeeze()\n",
    "                print(outputs.squeeze().shape)\n",
    "                print(targets.shape)\n",
    "                loss = criterion(outputs, targets)\n",
    "                print(loss)\n",
    "                y_pred = outputs.data.cpu().numpy().ravel()\n",
    "                y_true = targets.data.cpu().numpy().ravel()\n",
    "                for name, metric in metrics.items():\n",
    "                    if name == \"f1_score\":\n",
    "                        # Use a classification threshold of 0.1\n",
    "                        batchsummary[f\"{phase}_{name}\"].append(\n",
    "                            metric(y_true > 0, y_pred > 0.1)\n",
    "                        )\n",
    "                    else:\n",
    "                        batchsummary[f\"{phase}_{name}\"].append(\n",
    "                            metric(y_true.astype(\"uint8\"), y_pred)\n",
    "                        )\n",
    "\n",
    "                if phase == \"Train\":\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "        batchsummary[\"epoch\"] = epoch\n",
    "        epoch_loss = loss\n",
    "        batchsummary[f\"{phase}_loss\"] = epoch_loss.item()\n",
    "        print(\"{} Loss: {:.4f}\".format(phase, loss))\n",
    "    for field in fieldnames[3:]:\n",
    "        batchsummary[field] = np.mean(batchsummary[field])\n",
    "        print(batchsummary)\n",
    "        # deep copy the model\n",
    "        if phase == \"Test\" and loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_model_wts = copy.deepcopy(net.state_dict())\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print(\n",
    "    \"Training complete in {:.0f}m {:.0f}s\".format(time_elapsed // 60, time_elapsed % 60)\n",
    ")\n",
    "print(\"Lowest Loss: {:4f}\".format(best_loss))\n",
    "\n",
    "# load best model weights\n",
    "net.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
