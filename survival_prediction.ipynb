{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK\n",
    "import itertools\n",
    "import sys\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchvision import models\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "SOURCE_PATH = Path(os.getcwd()) / 'src'\n",
    "\n",
    "if SOURCE_PATH not in sys.path:\n",
    "    sys.path.append(SOURCE_PATH)\n",
    "\n",
    "from src.extraction import (\n",
    "    extract_images_in_survival_order,\n",
    ")\n",
    "\n",
    "from src.plots import (\n",
    "    plot_observation,\n",
    "    plot_deeplab_mobile_predictions,\n",
    "    plot_mobile_prediction_from_path\n",
    ")\n",
    "\n",
    "from src.deeplab_mobile.modelling import(\n",
    "    select_images_input,\n",
    "    get_deeplab_mobile_model,\n",
    "    train_deeplab_mobile\n",
    ")\n",
    "\n",
    "from src.deeplab_mobile.segdataset import(\n",
    "    get_mobile_dataloaders\n",
    ")\n",
    "\n",
    "from src.utils import(\n",
    "    LOGS_FILE_PATH,\n",
    "    TYPE_NAMES\n",
    ")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(os.getcwd()) / 'data' / 'HGG'\n",
    "survival = pd.read_csv(data_path.parent /'survival_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ids = survival['BraTS19ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2, t1ce, t1, flair, seg = extract_images_in_survival_order(data_path, dir_ids)\n",
    "images = [t2, t1ce, t1, flair, seg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(TYPE_NAMES)):\n",
    "    survival[TYPE_NAMES[i]] = images[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'flair_totalpipe_old.pt'\n",
    "model = torch.load(Path(os.getcwd()) / 'models' / modelname)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair_segout = []\n",
    "\n",
    "for i in range(len(survival)):\n",
    "    input_tensor = torch.tensor(survival['flair'][i]).expand(3, -1, -1).type(torch.ShortTensor).float().unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)['out'][0][0]\n",
    "    flair_segout.append(np.array(output))\n",
    "\n",
    "survival['flair_seg'] = flair_segout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = []\n",
    "for i in range(len(survival)):\n",
    "    if 'ALIVE' in survival['Survival'].loc[i]:\n",
    "        to_drop.append(i)\n",
    "        \n",
    "        \n",
    "survival.drop(to_drop, inplace=True)\n",
    "survival = survival.dropna().reset_index(drop=True)\n",
    "print(len(survival))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survival['Survival'] = survival['Survival'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Survival_Dataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 images,\n",
    "                 targets,\n",
    "                 fraction = 0.1,\n",
    "                 subset = None,\n",
    "                 image_color_mode = \"rgb\"\n",
    "                 ) -> None:\n",
    "\n",
    "        if image_color_mode not in [\"rgb\", \"grayscale\"]:\n",
    "            raise ValueError(\n",
    "                f\"{image_color_mode} is an invalid choice. Please enter from rgb grayscale.\"\n",
    "            )\n",
    "\n",
    "        self.image_color_mode = image_color_mode\n",
    "\n",
    "        if subset not in [\"Train\", \"Test\"]:\n",
    "            raise (ValueError(\n",
    "                f\"{subset} is not a valid input. Acceptable values are Train and Test.\"\n",
    "            ))\n",
    "\n",
    "        self.fraction = fraction\n",
    "        self.images = images\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        image = self.images[index]\n",
    "        target = self.targets[index]\n",
    "        \n",
    "        sample = {\"image\": image, \"target\": target}\n",
    "        sample[\"image\"] = torch.tensor(sample[\"image\"]).expand(3, -1, -1).type(torch.ShortTensor)\n",
    "        sample[\"target\"] = target\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_survival_dataloaders(images, target, batch_size=14):\n",
    "    image_datasets = {\n",
    "        x: Survival_Dataset(\n",
    "            images,\n",
    "            target,\n",
    "            subset=x)\n",
    "        for x in ['Train', 'Test']\n",
    "    }\n",
    "\n",
    "    dataloaders = {\n",
    "            x: DataLoader(image_datasets[x],\n",
    "                        batch_size=batch_size,\n",
    "                        )\n",
    "            for x in ['Train', 'Test']\n",
    "        }\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = get_survival_dataloaders(survival['flair'].values, survival['Survival'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
