{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK\n",
    "import itertools\n",
    "import sys\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "SOURCE_PATH = Path(os.getcwd()) / 'src'\n",
    "\n",
    "if SOURCE_PATH not in sys.path:\n",
    "    sys.path.append(SOURCE_PATH)\n",
    "\n",
    "from src.extraction import (\n",
    "    get_images_lists_from_path,\n",
    "    get_images_lists_from_more_paths\n",
    ")\n",
    "\n",
    "from src.plots import (\n",
    "    plot_observation\n",
    ")\n",
    "\n",
    "from src.loading import (\n",
    "    load_images_from_paths\n",
    ")\n",
    "\n",
    "from src.modelling import (\n",
    "    deeplab_finetuning\n",
    ")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_to_use = 't1'\n",
    "seg_path = Path(os.getcwd()) / 'data_extracted' / 'seg'\n",
    "input_path = Path(os.getcwd()) / 'data_extracted' / type_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess in notebook --> not used for finetuning\n",
    "images, segs = load_images_from_paths(input_path, seg_path)\n",
    "\n",
    "images_inputs = pad_sequence([torch.tensor(x) for x in images], batch_first=True)\n",
    "seg_inputs = pad_sequence([torch.tensor(x) for x in segs], batch_first=True)\n",
    "images_dataloader = DataLoader(images_inputs, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Created\n",
      "Parameters defined\n",
      "Dataloaders created\n",
      "Epoch 1/1\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [32:56<00:00, 29.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [02:36<00:00,  9.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0023\n",
      "{'epoch': 1, 'Train_loss': 0.01524023525416851, 'Test_loss': 0.002331365132704377, 'Train_f1_score': 0.1261710393621117, 'Test_f1_score': 0.4995879586896458}\n",
      "Training complete in 35m 34s\n",
      "Lowest Loss: 0.002331\n"
     ]
    }
   ],
   "source": [
    "path = str(input_path.parent)\n",
    "deeplab_finetuning(path, 't2', 'seg', 'models', epochs=1, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'weights.pt'\n",
    "model = torch.load(Path(os.getcwd()) / 'models' / modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move the input and model to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(input_batch)['out'][0]\n",
    "output_predictions = output.argmax(0)\n",
    "\n",
    "# create a color pallette, selecting a color for each class\n",
    "palette = torch.tensor([2 ** 25 - 1, 2 ** 15 - 1, 2 ** 21 - 1])\n",
    "colors = torch.as_tensor([i for i in range(21)])[:, None] * palette\n",
    "colors = (colors % 255).numpy().astype(\"uint8\")\n",
    "\n",
    "r = Image.fromarray(output_predictions.byte().cpu().numpy()).resize(input_image.size)\n",
    "r.putpalette(colors)\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(15, 4))\n",
    "ax[0].set_title('input image')\n",
    "ax[0].axis('off')\n",
    "ax[0].imshow(input_image)\n",
    "ax[1].set_title('segmented output')\n",
    "ax[1].axis('off')\n",
    "ax[1].imshow(r)\n",
    "plt.savefig(\"segmented_output.png\", bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
    "from torchvision import models\n",
    "\n",
    "def createDeepLabv3(outputchannels=1):\n",
    "    \"\"\"DeepLabv3 class with custom head\n",
    "    Args:\n",
    "        outputchannels (int, optional): The number of output channels\n",
    "        in your dataset masks. Defaults to 1.\n",
    "    Returns:\n",
    "        model: Returns the DeepLabv3 model with the ResNet101 backbone.\n",
    "    \"\"\"\n",
    "    model = models.segmentation.deeplabv3_resnet101(pretrained=True,\n",
    "                                                    progress=True)\n",
    "    model.classifier = DeepLabHead(2048, outputchannels)\n",
    "    # Set the model in training mode\n",
    "    model.train()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from torch.utils import data\n",
    "\n",
    "import datahandler\n",
    "from model import createDeepLabv3\n",
    "from trainer import train_model\n",
    "\n",
    "\n",
    "@click.command()\n",
    "@click.option(\"--data-directory\",\n",
    "              required=True,\n",
    "              help=\"Specify the data directory.\")\n",
    "@click.option(\"--exp_directory\",\n",
    "              required=True,\n",
    "              help=\"Specify the experiment directory.\")\n",
    "@click.option(\n",
    "    \"--epochs\",\n",
    "    default=25,\n",
    "    type=int,\n",
    "    help=\"Specify the number of epochs you want to run the experiment for.\")\n",
    "@click.option(\"--batch-size\",\n",
    "              default=4,\n",
    "              type=int,\n",
    "              help=\"Specify the batch size for the dataloader.\")\n",
    "def main(data_directory, exp_directory, epochs, batch_size):\n",
    "    # Create the deeplabv3 resnet101 model which is pretrained on a subset\n",
    "    # of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.\n",
    "    model = createDeepLabv3()\n",
    "    model.train()\n",
    "    data_directory = Path(data_directory)\n",
    "    # Create the experiment directory if not present\n",
    "    exp_directory = Path(exp_directory)\n",
    "    if not exp_directory.exists():\n",
    "        exp_directory.mkdir()\n",
    "\n",
    "    # Specify the loss function\n",
    "    criterion = torch.nn.MSELoss(reduction='mean')\n",
    "    # Specify the optimizer with a lower learning rate\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    # Specify the evaluation metrics\n",
    "    metrics = {'f1_score': f1_score, 'auroc': roc_auc_score}\n",
    "\n",
    "    # Create the dataloader\n",
    "    dataloaders = datahandler.get_dataloader_single_folder(\n",
    "        data_directory, batch_size=batch_size)\n",
    "    _ = train_model(model,\n",
    "                    criterion,\n",
    "                    dataloaders,\n",
    "                    optimizer,\n",
    "                    bpath=exp_directory,\n",
    "                    metrics=metrics,\n",
    "                    num_epochs=epochs)\n",
    "\n",
    "    # Save the trained model\n",
    "    torch.save(model, exp_directory / 'weights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
