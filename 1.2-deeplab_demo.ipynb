{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK\n",
    "import itertools\n",
    "import sys\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "SOURCE_PATH = Path(os.getcwd()) / \"src\"\n",
    "\n",
    "if SOURCE_PATH not in sys.path:\n",
    "    sys.path.append(SOURCE_PATH)\n",
    "\n",
    "from src.extraction import get_images_lists_from_path, get_images_lists_from_more_paths\n",
    "\n",
    "from src.plots import plot_observation\n",
    "\n",
    "from src.loading import load_images_from_paths\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_to_use = \"t2\"\n",
    "seg_path = Path(os.getcwd()) / \"data_extracted\" / \"seg\"\n",
    "input_path = Path(os.getcwd()) / \"data_extracted\" / type_to_use\n",
    "images, segs = load_images_from_paths(input_path, seg_path)\n",
    "\n",
    "modelname = \"t2_20e_mobilenet_mse.pt\"\n",
    "model = torch.load(Path(os.getcwd()) / \"models\" / modelname)\n",
    "model.eval()\n",
    "\n",
    "output_save_path = Path(os.getcwd()) / \"output\"\n",
    "if not os.path.isdir(output_save_path):\n",
    "    os.mkdir(output_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "indexes_predict = [32, 36, 48]\n",
    "\n",
    "for i in indexes_predict:\n",
    "    input_image = Image.fromarray(images[i])\n",
    "    true_segments = Image.fromarray(segs[i])\n",
    "\n",
    "    input_tensor = preprocess(input_image)\n",
    "    input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)[\"out\"][0]\n",
    "    output_predictions = torch.amax(output, 0).numpy()\n",
    "\n",
    "    # create a color pallette, selecting a color for each class\n",
    "    palette = torch.tensor([2 ** 25 - 1, 2 ** 15 - 1, 2 ** 21 - 1])\n",
    "    colors = torch.as_tensor([i for i in range(21)])[:, None] * palette\n",
    "    colors = (colors % 255).numpy().astype(\"uint8\")\n",
    "\n",
    "    threshold_min = np.percentile(output_predictions, 90)\n",
    "    threshold_mid = np.percentile(output_predictions, 95)\n",
    "    threshold_max = np.percentile(output_predictions, 99)\n",
    "\n",
    "    output_pred = output_predictions\n",
    "    output_pred = np.where(output_predictions > threshold_min, threshold_min, 0)\n",
    "    output_pred = np.where(\n",
    "        output_predictions > threshold_mid, threshold_mid, output_pred\n",
    "    )\n",
    "    output_pred = np.where(\n",
    "        output_predictions > threshold_max, threshold_max, output_pred\n",
    "    )\n",
    "\n",
    "    f, ax = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    ax[0].set_title(\"input image\")\n",
    "    ax[0].axis(\"off\")\n",
    "    ax[0].imshow(input_image)\n",
    "    ax[1].set_title(\"segmented output\")\n",
    "    ax[1].axis(\"off\")\n",
    "    ax[1].imshow(output_pred)\n",
    "    ax[2].set_title(\"ground truth\")\n",
    "    ax[2].axis(\"off\")\n",
    "    ax[2].imshow(true_segments)\n",
    "    plt.show()\n",
    "\n",
    "    np.save(str(output_save_path) + f\"/segmented_{i}.npy\", output_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
