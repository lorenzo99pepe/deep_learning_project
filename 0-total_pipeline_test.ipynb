{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK\n",
    "import itertools\n",
    "import sys\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchvision import models\n",
    "from src.loading import get_dataloader_single_folder\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "SOURCE_PATH = Path(os.getcwd()) / 'src'\n",
    "\n",
    "if SOURCE_PATH not in sys.path:\n",
    "    sys.path.append(SOURCE_PATH)\n",
    "\n",
    "from src.extraction import (\n",
    "    export_all_images_jpeg,\n",
    "    export_images_list_jpeg,\n",
    "    get_images_lists_from_path,\n",
    "    get_images_lists_from_more_paths\n",
    ")\n",
    "\n",
    "from src.plots import (\n",
    "    plot_observation\n",
    ")\n",
    "\n",
    "from src.modelling import (\n",
    "    train_model\n",
    ")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgg = Path(os.getcwd()) / 'data' / 'HGG'\n",
    "lgg = Path(os.getcwd()) / 'data' / 'LGG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2, t1ce, t1, flair, seg = get_images_lists_from_path(hgg)\n",
    "t2l, t1cel, t1l, flairl, segl = get_images_lists_from_path(lgg)\n",
    "\n",
    "type_names = ['t2', 't1', 't1ce', 'flair', 'seg']\n",
    "images = [t2, t1, t1ce, flair, seg]\n",
    "imagesl = [t2l, t1l, t1cel, flairl, segl]\n",
    "all_images = get_images_lists_from_more_paths([hgg,lgg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_observation(images, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_observation(imagesl, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_observation(all_images, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_to_use = 'flair'\n",
    "images_chosen = np.array([images[type_names.index(type_to_use)][i] for i in range(len(images[type_names.index(type_to_use)]))])\n",
    "images_seg = np.array([images[type_names.index('seg')][i] for i in range(len(images[type_names.index('seg')]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.segmentation.deeplabv3_mobilenet_v3_large(\n",
    "    pretrained=False,\n",
    "    progress=True,\n",
    "    num_classes = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Dataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 images_list,\n",
    "                 seg_list,\n",
    "                 fraction = 0.1,\n",
    "                 subset = None,\n",
    "                 transforms = None,\n",
    "                 image_color_mode = \"rgb\",\n",
    "                 mask_color_mode = \"rgb\") -> None:\n",
    "\n",
    "        if image_color_mode not in [\"rgb\", \"grayscale\"]:\n",
    "            raise ValueError(\n",
    "                f\"{image_color_mode} is an invalid choice. Please enter from rgb grayscale.\"\n",
    "            )\n",
    "        if mask_color_mode not in [\"rgb\", \"grayscale\"]:\n",
    "            raise ValueError(\n",
    "                f\"{mask_color_mode} is an invalid choice. Please enter from rgb grayscale.\"\n",
    "            )\n",
    "\n",
    "        self.image_color_mode = image_color_mode\n",
    "        self.mask_color_mode = mask_color_mode\n",
    "        self.transforms = transforms\n",
    "\n",
    "        if subset not in [\"Train\", \"Test\"]:\n",
    "            raise (ValueError(\n",
    "                f\"{subset} is not a valid input. Acceptable values are Train and Test.\"\n",
    "            ))\n",
    "        self.fraction = fraction\n",
    "        self.image_list = images_list\n",
    "        self.mask_list = seg_list\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        image = self.image_list[index]\n",
    "        mask = self.mask_list[index]\n",
    "        \n",
    "        sample = {\"image\": image, \"mask\": mask}\n",
    "        # if self.transforms:\n",
    "        #     sample[\"image\"] = torch.tensor(sample[\"image\"]).expand(3, -1, -1).type(torch.ShortTensor)\n",
    "        #     sample[\"mask\"] = torch.tensor(sample[\"mask\"]).expand(3, -1, -1).type(torch.ShortTensor)\n",
    "        sample[\"image\"] = torch.tensor(sample[\"image\"]).expand(3, -1, -1).type(torch.ShortTensor)\n",
    "        sample[\"mask\"] = torch.tensor(sample[\"mask\"]).expand(3, -1, -1).type(torch.ShortTensor)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_transforms = transforms.Compose(\n",
    "#     [transforms.ToTensor(),\n",
    "#     ])\n",
    "\n",
    "image_datasets = {\n",
    "        x: Custom_Dataset(\n",
    "            images_chosen,\n",
    "            images_seg,\n",
    "            transforms=None,\n",
    "            subset=x)\n",
    "        for x in ['Train', 'Test']\n",
    "    }\n",
    "\n",
    "dataloaders = {\n",
    "        x: DataLoader(image_datasets[x],\n",
    "                      batch_size=5,\n",
    "                      #shuffle=True, #to test without shuffle not done yet\n",
    "                      #num_workers=8\n",
    "                      )\n",
    "        for x in ['Train', 'Test']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "import csv\n",
    "\n",
    "since = time.time()\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_loss = 1e10\n",
    "metrics = {'f1_score': f1_score}\n",
    "num_epochs = 2\n",
    "bpath = Path(os.getcwd()) / 'models'\n",
    "\n",
    "#criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Specify the optimizer with a lower learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "# Initialize the log file for training and testing loss and metrics\n",
    "fieldnames = ['epoch', 'Train_loss', 'Test_loss'] + \\\n",
    "    [f'Train_{m}' for m in metrics.keys()] + \\\n",
    "    [f'Test_{m}' for m in metrics.keys()]\n",
    "\n",
    "with open(os.path.join(bpath, 'log.csv'), 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs))\n",
    "    print('-' * 10)\n",
    "        # Each epoch has a training and validation phase\n",
    "        # Initialize batch summary\n",
    "    batchsummary = {a: [0] for a in fieldnames}\n",
    "\n",
    "    for phase in ['Train', 'Test']:\n",
    "        if phase == 'Train':\n",
    "            model.train()  # Set model to training mode\n",
    "        else:\n",
    "            model.eval()  # Set model to evaluate mode\n",
    "\n",
    "        # Iterate over data.\n",
    "        for sample in tqdm(iter(dataloaders[phase])):\n",
    "            inputs = sample['image'].float()\n",
    "            masks = sample['mask'].float()\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(phase == 'Train'):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs['out'], masks)\n",
    "                y_pred = outputs['out'].data.cpu().numpy().ravel()\n",
    "                y_true = masks.data.cpu().numpy().ravel()\n",
    "                for name, metric in metrics.items():\n",
    "                    if name == 'f1_score':\n",
    "                        # Use a classification threshold of 0.1\n",
    "                        batchsummary[f'{phase}_{name}'].append(\n",
    "                            metric(y_true > 0, y_pred > 0.1))\n",
    "                    else:\n",
    "                        batchsummary[f'{phase}_{name}'].append(\n",
    "                            metric(y_true.astype('uint8'), y_pred))\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'Train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "        batchsummary['epoch'] = epoch\n",
    "        epoch_loss = loss\n",
    "        batchsummary[f'{phase}_loss'] = epoch_loss.item()\n",
    "        print('{} Loss: {:.4f}'.format(phase, loss))\n",
    "    for field in fieldnames[3:]:\n",
    "        batchsummary[field] = np.mean(batchsummary[field])\n",
    "        print(batchsummary)\n",
    "    with open(os.path.join(bpath, 'log.csv'), 'a', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writerow(batchsummary)\n",
    "        # deep copy the model\n",
    "        if phase == 'Test' and loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "    time_elapsed // 60, time_elapsed % 60))\n",
    "print('Lowest Loss: {:4f}'.format(best_loss))\n",
    "\n",
    "# load best model weights\n",
    "model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_exp_name = 'flair_totalpipe_final'\n",
    "torch.save(model, str(Path(os.getcwd()) / 'models' / (model_exp_name + '.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'flair_totalpipe_final.pt'\n",
    "model = torch.load(Path(os.getcwd()) / 'models' / modelname)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_predict = np.arange(0, 20)\n",
    "\n",
    "for i in indexes_predict:\n",
    "    input_tensor = torch.tensor(images[type_names.index(type_to_use)][i]).expand(3, -1, -1).type(torch.ShortTensor).float()\n",
    "    truth = torch.tensor(images[type_names.index('seg')][i]).expand(3, -1, -1).type(torch.ShortTensor).float()\n",
    "\n",
    "    input_batch = input_tensor.unsqueeze(0) \n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)['out'][0]\n",
    "    output_predictions = output #.argmax(0)\n",
    "\n",
    "    # create a color pallette, selecting a color for each class\n",
    "    palette = torch.tensor([2 ** 25 - 1, 2 ** 15 - 1, 2 ** 21 - 1])\n",
    "    colors = torch.as_tensor([i for i in range(21)])[:, None] * palette\n",
    "    colors = (colors % 255).numpy().astype(\"uint8\")\n",
    "\n",
    "    # r = Image.fromarray(output_predictions.byte().cpu().numpy()).resize(input_tensor.size)\n",
    "    # r.putpalette(colors)\n",
    "\n",
    "    f, ax = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    ax[0].set_title('input image')\n",
    "    ax[0].axis('off')\n",
    "    ax[0].imshow(input_tensor[0])\n",
    "    ax[1].set_title('segmented output')\n",
    "    ax[1].axis('off')\n",
    "    ax[1].imshow(output_predictions[0])\n",
    "    ax[2].set_title('ground truth')\n",
    "    ax[2].axis('off')\n",
    "    ax[2].imshow(truth[0])\n",
    "    #plt.savefig(\"segmented_output.png\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(str(bpath) + '/log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all the values with respect to the epochs\n",
    "df.plot(x='epoch',figsize=(15,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
